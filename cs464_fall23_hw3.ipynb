{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmlJ7FFJGA3k"
      },
      "source": [
        "**<h5></h5>**\n",
        "**<h1><center>CS 464</center></h1>**\n",
        "**<h1><center>Introduction to Machine Learning</center></h1>**\n",
        "**<h1><center>Fall 2023</center></h1>**\n",
        "**<h1><center>Homework 3</center></h1>**\n",
        "<h4><center>Due: December 29, 2023 23:59 (GMT+3)</center></h4>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUQigqxM4JlE"
      },
      "source": [
        "## **CIFAR-100 Inpainting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JLXD3sTR8Yv"
      },
      "source": [
        "### **Homework Description**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFNaqLRzD75v"
      },
      "source": [
        "In this assignment, you are asked to design and train a convolutional neural network model for the image inpainting task. In short, inpainting is a process of filling in the missing parts of an image. You will be applying this task on the preprocessed CIFAR-100 dataset, which is created for this homework by processing the original [CIFAR-100](https://www.cs.toronto.edu/~kriz/cifar.html?ref=assemblyai.com) images. It contains RGB real-life images with the size of 28x28 pixel resolution. You can see a subset of the dataset below. The download link of the dataset is provided in the following parts.\n",
        "\n",
        "![CIFAR-100 Samples](https://drive.google.com/uc?export=view&id=1drp11GJ3QnRivkYLR0nh9RVOi9lnIh8o)\n",
        "\n",
        "**Using PyTorch is mandatory** for this assignment. You are requested to **submit only a single *.ipynb file** in your submissions (no report needed). If you want to provide further explanations about your work, you can add Markdown cells for this purpose. From [this link](https://www.markdownguide.org/), you can get familiar with the Markdown syntax if you need. Upload your homework with the following filename convention: **\\<BilkentID\\>\\_\\<Name\\>\\_\\<Surname\\>.ipynb**\n",
        "\n",
        "Note that this assignment needs a CUDA-enabled GPU to be able to train the models in a reasonable time. If you do not have one, it is suggested to use the [Colab](https://colab.research.google.com/) environment.\n",
        "\n",
        "**Contact:** [Ahmet Burak Yıldırım](mailto:a.yildirim@bilkent.edu.tr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMvuukCeSkRE"
      },
      "source": [
        "### **Importing the Libraries**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcipuzDyJyMT"
      },
      "source": [
        "In the cell below,  some utilities that you can make use of in this assignment are imported. You can edit these imports considering your implementation as long as you use PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v0OO4-6SmNV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import random\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLoc5OoAKDtr"
      },
      "source": [
        "### **Environment Check**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfGyOffcKG7u"
      },
      "source": [
        "In the cell below, you can test whether hardware acceleration with GPU is enabled in your machine or not. If it is enabled, the printed device should be 'cuda'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaTYscuOLbjc"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Current device:', device)\n",
        "\n",
        "if device.type == 'cuda':\n",
        "    print('GPU Name:', torch.cuda.get_device_name(0))\n",
        "    print('Total GPU Memory:', round(torch.cuda.get_device_properties(0).total_memory/1024**3,1), 'GB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBK2IftRSvHf"
      },
      "source": [
        "### **Setting Library Seeds for Reproducibility**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOZICZTbMc2-"
      },
      "source": [
        "**DO NOT CHANGE**<br>\n",
        "To make a fair evaluation, the seed values are set for random sampling methods in PyTorch, NumPy, and Python random library. Please do not change these values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3M5lcMwQStjy"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJ1GUeFfSzN_"
      },
      "outputs": [],
      "source": [
        "seed_everything(464)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h60dtOt5R_aE"
      },
      "source": [
        "### **Preparing the Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dzcz2jwcNKfK"
      },
      "source": [
        "The CIFAR-100 dataset is downloadable from [this link](https://drive.google.com/file/d/1KiymtjUjuEJjUTO_qB9ifpLC_UvJEhoL/view?usp=share_link). If you are using Colab or a Linux machine, you can uncomment and run the below cell to download and extract the dataset automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85HQtprVSD3p"
      },
      "outputs": [],
      "source": [
        "# import gdown # Library to download files from Google Drive\n",
        "# !gdown 1KiymtjUjuEJjUTO_qB9ifpLC_UvJEhoL # Google Drive ID of the zip file to be downloaded\n",
        "# !unzip -oq cifar100.zip # Unzip the file downloaded. Options -o and -q overwrites the files if exists already and disables printing out the extracted files, respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhEiiIYxTBi9"
      },
      "source": [
        "### **Implementing a Custom Dataset [25 Points]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGpUjWbWOBpJ"
      },
      "source": [
        "In this part, you are requested to implement a custom PyTorch dataset class that reads CIFAR-100 images from a dataset split folder. There are two split folders called train and test in the dataset. The model class should take the root directory of a split in the \\_\\_init\\_\\_ function and read the images accordingly. Before returning the requested images, you should apply the following steps:\n",
        "\n",
        "* Apply bicubic interpolation using PIL to resize the images from (28,28) to (32,32) resolution.\n",
        "* Convert images to Tensor object\n",
        "* Normalize tensor values to scale them in the range of (-1,1)\n",
        "\n",
        "Note that reading images in the \\_\\_getitem\\_\\_ function makes the training process slow for this dataset because reading such small-sized images as a batch is slower than the forward pass process of a simple neural network. Therefore, it is suggested to read and store the images in an array in the \\_\\_init\\_\\_ function and return them in the \\_\\_getitem\\_\\_ function when they are requested by the DataLoader object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ongUJiujS_UE"
      },
      "outputs": [],
      "source": [
        "class CifarDataset(Dataset):\n",
        "    def __init__(self, root_dir):\n",
        "        pass # TODO\n",
        "\n",
        "    def __len__(self):\n",
        "        pass # TODO\n",
        "\n",
        "    def __getitem__(self, data_id):\n",
        "        pass # TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqaS0ePeWzd3"
      },
      "source": [
        "Create a dataset and a data loader object for training and test splits. Set batch sizes to 64 and 512 for training and test data loaders, respectively. Enable shuffling in the training data loader and disable it in the test data loader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-RUAYGdTuVn"
      },
      "outputs": [],
      "source": [
        "train_dataset = None # TODO\n",
        "train_dataloader = None # TODO\n",
        "\n",
        "test_dataset = None # TODO\n",
        "test_dataloader = None # TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqYREQNbpQeR"
      },
      "source": [
        "**Do not change** the below code. If your implementation is correct, you should be seeing a grid of CIFAR-100 images properly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnVU_VccT-Yi"
      },
      "outputs": [],
      "source": [
        "## Uncomment the cell when the dataloader is ready\n",
        "\n",
        "# images = next(iter(train_dataloader)) # Taking one batch from the dataloader\n",
        "# images = (images + 1) / 2\n",
        "# grid_img = torchvision.utils.make_grid(images[:20], nrow=10)\n",
        "# plt.axis('off')\n",
        "# plt.imshow(grid_img.permute(1, 2, 0))\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qx_XrpE44TlW"
      },
      "source": [
        "### **Constructing Convolutional Autoencoder Network [35 Points]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC8HgZSPmUhS"
      },
      "source": [
        "Autoencoder networks learn how to compress and reconstruct input data. It consists of two networks called the encoder and the decoder. The encoder network compresses the input data, and the decoder network regenerates the data from its compressed version. In this part, you are requested to implement an autoencoder model using convolutional layers. The architecture of the convolutional autoencoder is shown in the below figure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw4yXKnke3M_"
      },
      "source": [
        "![Convolutional Autoencoder Architecture](https://drive.google.com/uc?export=view&id=19RqHo2PatyoFl7om8OUxBRb1uYAVGmhF)\n",
        "\n",
        "The (in_channel, out_channel) pairs of the layers should be defined as follows:\n",
        "\n",
        "**Encoder:**\n",
        "- (3, 16)\n",
        "- (16, 32)\n",
        "- (32, 64)\n",
        "\n",
        "**Decoder:**\n",
        "- (64, 32)\n",
        "- (32, 16)\n",
        "- (16, 3)\n",
        "\n",
        "You are free to choose the kernel and padding sizes of the layers. In each layer, [2D batch normalization](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html) should be applied and the resulting values should be passed through a LeakyReLU layer with slope 0.2, which is the activation function. Since the image pixel value range is set to [-1,1] in the dataset, the outputs should be bounded so. Therefore, you should be using a Tanh activation function in the last layer instead of the normalization and LeakyReLU layers.\n",
        "\n",
        "In the encoder part of the network, use max pooling in each layer for decreasing the resolution by half. The stride size should be set to one for the convolution layers. In the decoder network, use [transposed convolution](https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html) (deconvolution) layers with stride two for increasing the resolution back."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHSbmwvcUMn6"
      },
      "outputs": [],
      "source": [
        "class CifarAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        pass # TODO\n",
        "\n",
        "    def forward(self, x):\n",
        "        pass # TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YwxmMCrWjtb"
      },
      "source": [
        "### **Implementing the Training Loop [15 Points]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xMSf3sofmJz"
      },
      "source": [
        "Define your training loop in this function. In the following parts, this function will be called to train the convolutional autoencoder. The input arguments are provided below. Apply the training progress and return a list of losses that are calculated on each epoch. You should sum the iteration losses up during an epoch and take the mean of them to calculate the running loss of that epoch.\n",
        "\n",
        "To be able to learn inpainting, you should mask the input images as follows:\n",
        "\n",
        "![CIFAR Masking](https://drive.google.com/uc?export=view&id=1tlB0mNH4B5dKfokoe162qWgXgPDnOQi2)\n",
        "\n",
        "Simply, you should set the input tensor columns starting from 16 to 32 as -1 (black pixel). For the loss function, you should use the original image as the ground truth image so that the network learns how to fill the masked area of the input image and output the restored image. Before assigning the black pixels, do not forget to clone the original image to use it later in the loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cifEP9HEWQde"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_dataloader, optimizer, loss_func, num_epochs):\n",
        "    pass # TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms6LRikETyds"
      },
      "source": [
        "### **Implementing the Evaluation Function [15 Points]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XTr6dpe-0NN"
      },
      "source": [
        "Implement an evaluation function that returns the mean MSE calculated over the test dataset samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JW-RK7vDT3l9"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_dataloader):\n",
        "    pass # TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjkRLMF0ZCtk"
      },
      "source": [
        "### **Inpainting Visualization Function**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI4ZNkVq_onm"
      },
      "source": [
        "The below code will be used to visualize the outputs of the trained models later. **Do not change the codes in the cell**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAuNmuIelqzI"
      },
      "outputs": [],
      "source": [
        "def visualize_inpainting(model, dataset):\n",
        "    seed_everything(464)\n",
        "    dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
        "    images = next(iter(dataloader)) # Taking one batch from the dataloader\n",
        "    images = images\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      masked_images = images.clone()\n",
        "      masked_images[:,:,:,16:] = -1\n",
        "      inpainted_images = model(masked_images.cuda()).cpu()\n",
        "    images = (images + 1) / 2\n",
        "    masked_images = (masked_images + 1) / 2\n",
        "    inpainted_images = (inpainted_images + 1) / 2\n",
        "    images_concat = torch.cat((images, masked_images, inpainted_images), dim=2)\n",
        "    grid_img = torchvision.utils.make_grid(images_concat, nrow=10)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(grid_img.permute(1, 2, 0))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JOGHIOakmL-"
      },
      "source": [
        "### **Training and Evaluating the Model [10 Points]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYdoryMh_9HN"
      },
      "source": [
        "Define your loss function as MSE, set learning rate to 2e-4, create Adam optimizer, and set number of epochs to 50. Later, call the train_model function that you implemented. Visualize the returned losses on a plot (loss vs. epoch). Lastly, call evaluate_model function that you implemented and print the mean square error that your model reached on the test dataset. Also, call the visualize_inpainting function to observe the final inpainting results on the test dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JhkdYbwiw0s"
      },
      "outputs": [],
      "source": [
        "seed_everything(464)\n",
        "# model = CifarAutoencoder() ## Uncomment when the model is implemented\n",
        "\n",
        "# TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgiD1WG-ZRgf"
      },
      "outputs": [],
      "source": [
        "# visualize_inpainting(model, test_dataset) ## Uncomment when the model is trained"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}